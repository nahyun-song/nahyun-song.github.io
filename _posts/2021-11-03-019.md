---
layout: single
title:  "20211103 데이터 불균형/XAI"
categories: AI_bootcamp
---

# 1. 데이터 불균형

1. 불균형 데이터 : 특정 레이블의 값이 다른 레이블에 비해 과도하게 많은 데이터

2. 스케일링
- `StandardScaler` : 불균형한 피처를 정규분포 형태로 변환

3. 로그 변환
- 데이터 분포가 심하게 왜곡되어 있을 경우 적용하는 기법
- 원래 값을 로그 값으로 변환하기 때문에 상대적을 적은 값(로그)으로 변환해 데이터 분포도의 왜곡을 개선한 후 모델을 판단할 수 있다

4. 이상치 제거
- IQR을 구하고 이 범위 밖에 있는 값들을 이상치로 여겨 제거하는 방식
- 상관도를 통해 타겟 피쳐와의 음의 상관도가 높은 데이터들을 제거 -> 성능을 높일 수 있음

5. 샘플링
- Under smpling : 유의미하다고 판단되는 데이터만 남기는 방식. majority class를 샘플링하여 샘플 수를 줄이는 방식으로 작동한다
    + 장점 : 데이터 균형을 맞추는 빠르고 쉬운 방법
    + 단점 : 잠재적으로 정보의 가치가 높은 데이터도 버려질 수 있다 -> 유용한 데이터가 사라질 위험이 있다\
        의사결정경계에 있는 데이터를 삭제하게 되는 경우 학습에 악영향을 미친다.
        + `RandomUnderSampler` : 대상 클래스의 데이터 하위 집합을 무작위로 선택하여 데이터의 균형을 맞추는 빠르고 쉬운 방법
- Over sampling : 소수 범주의 집합에서 무작위로 데이터를 추출하여 집합을 만들고, 이를 기존 집합에 더하는 방법
    + 장점 : 모든 데이터를 사용할 수 있다
    + 단점 : 데이터 수를 증가시키므로 계산에 필요한 시간이 늘어나거나 과대적합의 위험이 있다
        + SMOTE : 소수 클래스에서 각각의 샘플들의 KNN을 찾고 그 이웃들 사이에 선을 그어 무작위 점을 생성하는 방식\
            샘플들 사이의 특성을 반영한 데이터가 생성되어 과대적합에 강한 데이터가 생성된다
        + ADASYN : SMOTE의 개선된 버전. 데이터의 밀도 분포를 계산하여 범주마다 다른 양의 데이터를 합성하는 방식

4. Cost-sensitive learning : 소수의 클래스에 대한 cost값에 가중치를 더 많이 주어 균형잡힌 학습이 가능하게 하는 방법

# 2. XAI

1. XAI : 사람이 AI의 동작과 최종결과를 이해하고 올바르게 해석할 수 있고, 결과물이 생성되는 과정을 설명 가능하도록 해주는 기술
- 머신러닝 모형의 예측함수는 선형모형의 예측함수처럼 파라미터 추정값과 입력변수의 선형결합 형태로 나타나지 않기 때문에 설명력이 부족하다
- 특정한 예측결과가 어떻게 나오게 되었는지 설명하기 위해 XAI가 필요하다
- XAI 기법은 현상에 대한 모형의 예측을 설명하기 위한 것이지 현상 자체를 설명하기 위한 것이 아니다
- 인과적 추론을 위해서는 도메인 지식을 기반으로 한 통제된 실험이 수반되어야 한다

2. PDP (Partial Dependence Plot) : 관심있는 특정 입력변수를 제외한 다른 입력변수들의 값은 고정시킨 상태(상수 취급)에서 관심있는 입력변수의 값을 변화시키며(변수 취급) 예측값을 계산한 후, 그 값들의 평균을 낸 것\
    입력변수의 값을 변화시키는 범위는 보통 일정 간격으로 그리드를 만들어 사용한다
    + 단점 : 평균을 구하는 과정에서 상호작용(interaction)의 존재 같은 데이터의 특성이 함께 뭉게질 수 있다\
        입력변수 사이의 상관관계가 강하게 존재하면 값을 변화시키는 그리드 내의 특정 데이터 포인트는 발생 가능성이 낮은 값이나 발생할 수 없는 값이 포함될 수 있다
3. ICE plot : 평균을 구하지 않고 그리드 값의 변화에 따른 모든 관측치의 예측값을 그래프에 표시하는 방법
4. Surrogate model : 복잡하고 설명하기 힘든 모형(블랙박스 모형)을 단순하고 설명하기 쉬운 모형(대리 모형)으로 대신 설명하는 방법
    + 전역적 대리 모형(global surrogate model) : 블랙박스 모형을 학습시키는데 사용한 train 데이터의 **전부** 또는 일부를 설명 가능한 모형으로 다시 학습시켜서 블랙박스 모형을 설명하는 방식
        + 대리 모형이 얼마나 블랙박스 모형과 유사한 예측을 하는지 평가하기 위해 사용할 수 있는 방법 중 하나는 `R2`를 계산해보는 것
        + `R2`의 값이 1에 가까우면 대리 모형과 블랙박스 모형의 예측 결과가 유사하다는 것이다
        + 이 값이 얼마 이상이어야 좋다는 절대적인 기준이 없기 때문에 데이터나 분야, 상황에 따라 그 기준이 천차만별이다
        + 터무니 없는 대리 모델을 걸러내는 데 있어 상당히 유용함
    ![](https://i.esdrop.com/d/9760phgt5lnm/fKdeHBkaLR.png)
    + 국소적 대리 모형(local surrogate model) : 블랙박스 모형의 **개별** 관측치를 설명하기 위한 모형
        + LIME(Local Interpretable Model-agnostic Explations) : 다양한 종류의 데이터에 대해 국소적 대리 모형을 생성하기 위해 제안된 방법론
            + 핵심 가정 : 비선형적인 패턴을 학습한 머신러닝 모형이라도 국소적으로 보면 선형 모형으로 설명할 수 있다
            + 단점 : 같은 관측값에 대해서도 대리모형을 만들때마다 결과값이 크게 달라질 수 있다


5. Shap : Shapley value(섀플리값)을 이용하여 예측에 대해 각 특성의 기여도를 계산하는 기법
- Shapley value : 특성의 모든 조합에 대해 특성 기여도를 계산하여 그 값을 평균낸 값
- 장점 : 특성 간의 상호작용을 고려하여 기여도를 계산한다 - 특성 간 상관관계가 높은 경우 특성 중요도 대신에 SHAP를 사용하는 것이 더 정확한 결과를 얻을 수 있다

6. XAI의 한계
- 모델의 해석력과 정확도에는 trade-off 관계가 있다 -> 모델 선택 시 모델의 높은 해석력을 위해 어느 정도의 퍼포먼스를 희생할 것인지에 대한 딜레마가 존재
- 설명력의 질을 파악하는 것이 매우 어렵기 때문에 어떤 XAI 설명력 기법도 절대적인 지표가 될 수 없다\
    (아직까지는 설명력을 해석하는데 정량적인 기준대신 사용자의 주관적, 정성적인 기준이 들어가는 경우가 많음)
