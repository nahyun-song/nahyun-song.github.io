---
layout: single
title:  "20211025 머신러닝 개요 및 프로세스/SVM"
categories: AI_bootcamp
---

# 1. 머신러닝이 무엇이며 이를 통해 우리가 할 수 있는 것은 무엇인지 알아보기.

- 머신러닝 : 명시적인 규칙을 코딩하지 않고 기계가 데이터로부터 학습하여 어떤 작업을 더 잘하도록 만드는 것
    + 훈련 세트에 데이터를 모아 학습 알고리즘에 주입
    + 학습 알고리즘이 모델 기반이면 훈련 세트에 모델을 맞추기 위해 모델 파라미터 조정
    + 알고리즘이 사례 기반이면 샘플을 기억하는 것으로 학습을 시키고 유사도를 측정하여 학습한 샘플과 새로운 샘플을 비교하는 식으로 일반화

# 2. 머신러닝의 전반적인 프로세스와 도전과제는 무엇인지? 그리고 전통적인 AI 방식과는 어떻게 다른지

1. 머신러닝의 프로세스
- 1. 비즈니스 이해 (Business Understanding)
    + 문제를 파악해가는 과정을 반복하면서 문제를 재정의하고 해결책을 정의
    + 비즈니스 목표 검토/ 데이터 분석 목표 수립/ 초기 가설 수립 수행
- 2. 데이터 이해 (Data Understanding)
    + 문제에 정확히 부학하는 데이터가 있는 경우는 거의 없다
    + 데이터 원본 식별 및 취득 / 데이터 탐색 (EDA/CDA) 수행
        + EDA : 개별 데이터의 분포, 가설이 맞는지 파악 / 결측치, 이상치 파악
        + CDA : 탐색으로 파악하기 애매한 정보는 통계적 분석도구(가설검정) 사용
- 3. 데이터 준비 (Data Preparation)
    + 더 좋은 결과를 얻기 위해 데이터의 형태를 조작하고 변환하는 과정 -> 하나의 잘 정리/정제된 데이터프레임을 얻는다
    + 데이터 정제 : 결측치/이상치 식별 및 조치\
      조치는 결측치 제거, 수치형의 경우 평균이나 중앙치로 대체하거나 범주형인 경우 mode값으로 대체, 간단한 예측 모델로 대체하는 방식이 일반적으로 이용된다.
    + 특성 공학(Feature Engineering) : 기존 변수를 사용해서 데이터에 정보를 추가하는 과정
- 4. 모델링 (Modelling)    
    + 모델링 과정 : 데이터셋 분리 -> 중요 변수 선정 -> 머신러닝 알고리즘을 적용하여 모델 생성 -> 하이퍼 파라미터 튜닝 -> 모델 테스트
- 5. 평가 (Evaluation)
    + 모델에 대한 최종 평가 : Test set 이용
    + 비즈니스 기대가치 평가 (비즈니스 목표에 부합되는지)
- 6. 배포 (Deployment)
    + 시스템 유효성 검사 : 배포된 모델이 고객 요구사항을 충족하는지
    + 프로젝트 이전 : 운영환경으로 이전
2. 머신러닝의 주요 도전 과제
- 나쁜 데이터
    + 충분하지 않은 양의 훈련 데이터 : 샘플이 작으면 데이터 잡음(Sampling noise)이 생김
       + Sampling noise :  우연에 의한 대표성이 없는 데이터 
    + 대표성이 없는 훈련 데이터 : 일반화가 잘 되려면 일반하기를 원하는 새로운 사례를 훈련 데이터가 잘 대표하는 것이 중요
       + Sampling bias : 샘플의 크기가 크더라도 표본 추출 방법이 잘못되면 대표성을 띠지 못할 수도 있다
    + 낮은 품질의 데이터 : 훈련 데이터가 에러, 이상치, 노이즈로 가득한 경우 시스템에 내재된 패턴을 찾기 어려워짐
    + 관련 없는 특성 : 성공적인 머신러닝 프로젝트의 핵심 요소는 훈련에 사용할 좋은 특성을 찾아내는 것이므로 관련 없는 특성이 적어야 학습시키기 좋다
- 나쁜 알고리즘
    + 훈련 데이터 과대적합 : 모델이 훈련 데이터에 너무 잘 맞지만 일반성이 떨어지는 경우\
      보통 훈련 데이터에 있는 노이즈에 비해 모델이 너무 복잡할 때 일어남
        + 파라미터 수가 적은 모델을 선택한다
        + 훈련 데이터에 있는 특성 수를 줄인다
        + 모델에 제약을 가하여 단순화시킨다 (하이퍼파라미터 튜닝)
        + 훈련 데이터 양을 늘린다
        + 훈련 데이터의 노이즈를 줄인다 (오류 수정, 이상치 제거)
        
    + 훈련 데이터 과소적합 : 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못하는 경우
        + 모델 파라미터가 더 많은 강력한 모델을 선택한다
        + 학습 알고리즘에 더 좋은 특성을 제공한다 (특성 공학)
        + 모델의 제약을 줄인다 (하이퍼파라미터 튜닝)
        
3. 머신러닝 VS. 전통적인 AI 방식
- 전통적인 AI 방식은 사람이 데이터에서 규칙이나 패턴을 찾아 알고리즘을 작성하였다면 머신러닝은 데이터만 주어지면 패턴을 감지하여 알고리즘을 훈련함\
  (데이터의 패턴이 변하더라도 자동으로 패턴을 인식)
- 머신러닝이 뛰어난 분야들
    + 기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제 : 하나의 머신러닝 모델이 코드를 간단하게 만들고 전통적인 방법보다 더 잘 수행되도록 할 수 있다
    + 전통적인 방식으로는 해결 방법이 없는 복잡한 문제 : 가장 뛰어난 머신러닝 기법으로 해결 방법을 찾을 수 있다
    + 유동적인 환경 : 머신러닝 시스템은 새로운 데이터에 적응할 수 있다
    + 복잡한 문제와 대량의 데이터에서 통할 얻기

# 3. 머신러닝 알고리즘을 위한 데이터 준비방법 + 특성 스케일링 방법

1. 데이터 정제
    + 결측치 처리
        + 해당 샘플 삭제 `dropna()`
        + 해당 측성 삭제 `drop()`
        + 채우기(0, 평균, 중간값) `SimpleImputer`
    + 이상치 처리
2. 텍스트와 범주형 특성 다루기
    + 텍스트에서 숫자로 변환 `OrdinalEncoder`, `OneHotEncoder`
3. 특성 스케일링 : 모든 특성의 범위를 같도록 만들어 주는 것
    + min-max 스케일링 (`MinMaxSclaer`) : 0~1 범위에 들도록 값을 이동하고 스케일을 조정\
      데이터에서 최솟값을 뺀 후 최댓값과 최솟값의 차이로 나눈다
    + 표준화 (`StandardScaler`) : 평균을 뺀 후 표준편차로 나누어 결과 분포의 분산이 1이 되도록 만듬
      min-max 스케일링과느 달리 범위의 상한과 하한이 없음
      이상치의 영향을 덜 받음
    + 스케일링은 전체 데이터가 아니라 **훈련 데이터에 대해서만** `fit()` 매서드를 적용해야 함
    

# 4. 서포트 벡터 머신(SVM)

1. 서포트 백터 머신 : 분류를 위한 기준 선(결정 경계)을 정의하는 모델
    - 매우 강력하고 선형이나 비선형 분류, 회귀, 이상치 탐색에도 사용할 수 있는 다목적 머신러닝 모델
    - 머신러닝에서 가장 인기 있는 모델
    - 특히 복잡한 분류 문제에 잘 들어맞으며 작거나 중간 크기의 데이터셋에 적합
    - 로지스틱 회귀 분류와는 다르게 클래스에 대한 확률을 제공하지 않음
    - 서포트 벡터 : 결정 경계에서 가장 가까운 데이터들
    - 마진 : 결정 경계와 서포트 벡터 사이의 거리
    
![](https://i.esdrop.com/d/9760phgt5lnm/ccjwXA0xh0.png)
    
2. 선형 SVM 분류
    - Large margin classification : 마진을 최대로 하는 결정 경계를 찾는 것
    - 하드 마진 분류 : 모든 데이터를 올바르게 분류하는 방법. 마진 오류가 하나도 발생하지 않도록 분류
        + 문제점 : 데이터가 선형적으로 구분될 수 있어야 올바르게 작동, 이상치에 민감, 과대적합 발생 가능성이 높음
    - 소프트 마진 분류 : 하드 마진 분류보다 유연한 모델. 전반적인 데이터의 특성을 고려하여 학습하는 방법
        + 문제점 : 과소적합 발생 가능성 있음
    - 파라미터 C
        + 낮게 설정하면 : 마진 오류가 많지만 일반화가 잘 된다 (과대적합 해결 방안)
        + 높게 설정하면 : 마진 오류가 적지만 일반화가 잘 되지 않는다 
    
3. 비선형 SVM 분류
    - 선형적으로 분류할 수 없는 데이터에 사용
    - 비선형 데이터셋을 다루기 위해 다항 특성을 추가하여 차원을 높임 -> 선형적으로 구분 가능
    - 다항식 커널 : 다항식 특성을 추가하는 것은 간단하고 작동도 잘 되지만 높은 차수의 다항식은 모델을 느리게 만듬
        + 커널 트릭 : 실제로는 특성을 추가하지 않으면서 다항식 특성을 많이 추가한 것과 같은 결과를 얻을 수 있는 방법
        + 모델이 과대적합이라면 -> 다항식의 차수를 줄여야 함
        + 모델이 과소적합이라면 -> 다항식의 차수를 늘려야 함
        + 파라미터 `coef0` : 모델이 높은 차수와 낮은 차수에 얼마나 영향을 받을지 조절. 고차항의 영향을 줄일 수 있다
    - 유사도 특성 : 각 샘플이 특정 랜드마크와 얼마나 닮았는지 측정하는 유사도 함수로 계산한 특성
        + 랜드마크를 선택하는 법 : 데이터셋에 있는 모든 샘플 위치에 설정
            + 장점 : 차원이 매우 커지기 떄문에 변환된 훈련 세트가 선형적으로 구분될 가능성이 높음
            + 단점 : 훈련 세트가 매우 클 경우 동일한 크기의 아주 많은 특성이 만들어지게 됨
    - 가우시안 RBF 커널 
    - 계산 복잡도
    
4. SVM 회귀
    - 제한된 마진 오류 안에서 마진 안에 가능한 한 많은 샘플이 들어가도록 학습 (마진은 하이퍼파라미터 `𝜺`로 조절)
    - 마진 안에서는 훈련 샘플이 추가되어도 모델의 예측에는 영향이 없기 때문에 `𝜺`에 민감하지 않다




























