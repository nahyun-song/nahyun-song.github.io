---
layout: single
title:  "20220125 클라우드 API를 활용한 빅데이터 분석"
categories: study
---

# **빅데이터와 클라우드**

## 1. 클라우드 서비스 프로바이더의 종류와 특징

**클라우드 서비스의 유형**
- SaaS(Software as a Service)
    + 클라우드 환경에서 운영되는 애플리케이션 서비스
    + 소프트웨어를 구입해서 PC에 설치하지 않아도 웹에서 소프트웨어를 빌려 쓸 수 있다.
- IaaS(Infrastructure as a Service)
    + 인터넷을 통해 서버와 스토리지 등 데이터센터 자원을 빌려 쓸 수 있는 서비스
    + 이용자는 직접 데이터센터를 구축할 필요 없이 클라우드 환경에서 필요한 인프라를 꺼내 쓰면 된다.
    + 때에 따라 필요한 컴퓨팅 인프라를 몇 분 또는 몇 시간 안에 IaaS로 꾸려 운영할 수 있다.
    + 물리적으로 만들어진 환경이 아니기 때문에 사용하지 않을 때 시스템을 해체하는 것도 손쉽다.
- PaaS(Platform as a Service)
    + 소프트웨어 서비스를 개발할 때 필요한 플랫폼을 제공하는 서비스
    + PaaS 운영 업체는 개발자가 소프트웨어를 개발할 때 필요한 API를 제공해 개발자가 좀 더 편하게 앱을 개발할 수 있게 돕는다.
    + 개발자가 개발을 하는 데 필요한 도구와 환경을 사용하고, 사용한 만큼만 비용을 내기 때문에 개발자로선 비용 부담을 덜 수 있다. 
    + 플랫폼 기반으로 애플리케이션을 개발하기 때문에 특정 플랫폼에 종속될 수 있다는 단점이 있다.

**퍼블릭 IaaS 서비스의 최강자 아마존 웹 서비스(AWS)**
- S3(Simple Storage Service)
    + 1byte ~ 5GB까지의 파일 1개 생성/저장/삭제 가능
    + 파일 생성 개수는 무한대
    + 네임스페이스는 버킷, 키, 오브젝트
    + 모든 오브젝트에 URL을 통한 접근 가능
    + 공유 가능
- EC2(Elastic Compute Cloud)
    + 아마존 클라우드 서비스에서 가장 핵심적이고 영향력 있는 서비스
    + 컴퓨팅 파워 사용료를 시간당 계산하는 유틸리티 컴퓨팅 개념 적용
        + 사용량이 집중되는 시간/기간에만 인스턴스를 필요한 만큼 생성하면 됨 -> 저렴하고 간단하게 컴퓨팅 인프라 문제 해결
    + 각 컴퓨팅용 인스턴스(가상 서버)를 탄력적으로 운용할 수 있게 개발됨
    + 젠 하이퍼 바이저 사용
    + X86 기반의 서버 인스턴스 제공
    + 윈도우/리눅스의 다양한 OS 제공
    + AMI라는 템플릿 이미지를 기반으로 가상 버신 구동
    + 루트 사용자로 가상 머신 접근 가능
- EMR(Elastic MapReduce)
    + MapReduce
        + 계산 프레임워크의 간결성 때문에 간단하게 텍스트 기반 데이터를 처리할 수 있다.
        + 실시간 처리나 반복 작업에는 아주 취약함
    + 간단하게 하둡을 미리 설치해놓은 것이라고 생각하면 됨
    + 인풋 또는 결과 파일은 S3에서 꺼내오거나 읽어옴
    + EMR API를 통해 경로만 지정해주면 된다.
    + 필요한 인스턴스의 개수만 지정해서 계산을 수행하게 되어 있음 -> 비교적 간단하게 맵리듀스 작업을 수행할 수 있다
    
**퍼블릭 PaaS 서비스의 선두주자 구글**
- 구글 앱엔진
    + 개발자가 구글 앱엔진의 API에 맞추어서 코드만 생성하면 확장이나 성능 이슈는 구글이 알아서 해결해줌
    + 사용자가 작성한 코드는 앱엔진의 프레임워크를 통해 객체화되어 사용자의 요청에 응답한다
    + 사용자가 늘어나면 앱엔진 프레임워크가 많은 객체를 만들어서 응답을 하는 방식
    + 사용자가 인프라에 대해 알 수 없다
        + 데이터를 저장하거나 URL에 접근하려면 별도의 API로 접근해야 함
- 구글 빅쿼리
    + SQL 기반의 쿼리를 아주 큰 데이터 셋에서 수행해주는 서비스
    + 맵리큐스 대비 약 20~30배 정도 빠르게 계산을 처리할 수 있다
    + 빠른 속도 : 수십억 건의 데이터를 수 초 안에 계산해낸다
    + 확장성 : TB급의 데이터를 처리할 수 있으며, 수백억 건의 레코드를 수용한다
    + 단순성 : SQL 기반의 쿼리 언어를 지원하기 때문에 사용이 단순하다
    + 공유 및 보안 : 그룹과 사용자 기반의 공유를 제어할 수 있고 SSL 커넥션을 통해 데이터 보안을 지원한다
    + 다양한 접근 방법 : 웹 브라우저, 커맨드라인 툴 그리고 REST API를 지원함으로써 다양한 방법으로 빅쿼리 서비스를 지원한다
- 구글 컴퓨트 엔진
    + 구글에서 제공하는 가상 인프라 서비스 (아마존으 EC2 서비스와 유사)
    + KVM(Kernel-base Virtual Machine)기반의 하이퍼 바이저 사용
    + 구글 클라우드 스토리지, 구글 빅쿼리 같은 클라우드 서비스와 연동 가능
    + 기존 가상 인프라 서비스 업체보다 약 50% 저렴
    + 가상 머신 OS로 우분투 기반의 구글 컴퓨트 엔진 리눅스와 센트오에스만 제공, 윈도우는 제공하지 않음
    + 탈부착 가능한 블록 디스크 제공(최대 1TB)
    + 방화벽 기능 제공
    + 이중화 및 스케일 아웃 부족 (2022 기준으로 확인해볼 것!)
    
**윈도우 진영의 클라우드 서비스, 애저(Azure)**
- 윈도우 애저 웹사이트
    + .Net이나 nodejs 같은 언어로 개발된 웹 애플리케이션을 간단하게 클라우드 형태로 배포하고 관리할 수 있게 해주는 가상 플랫폼 서비스
    + TFS 또는 깃 그리고 FTP를 통해 자신의 애플리케이션을 애저에서 생성한 웹사이트에 간단하게 배포/운영할 수 있다
    + 하나의 웹 애플리케이션에 가상 인스턴스를 3개까지 예약해놓을 수도 있다
    + 필요할 경우 데이터베이스 서비스, CDN 서비스 등과 연동 가능
- 가상 머신 서비스
    + 아마존 EC2와 유사한 서비스
    + 가상 머신을 생성/운영할 수 있게 도와준다
    + 윈도우, 리눅스 계열 모두 지원
    + 윈도우 Hyper V를 기반으로 동작
- 빅데이터 서비스
    + 온라인상에서 하둡이 미리 설치된 가상머신을 사용할 수 있게 한 하둡온애저 클라우드 서비스
    + ODBC 커넥터 제공 -> 기존의 비즈니스 분석용 툴과 연동 가능 (엑셀, 파워피봇 등)
    + 기존의 애저 클라우드에 있는 데이터는 적브할 수 없고 해석할 데이터를 별도로 올려야 하는 번거로움이 있다
    
**정리**
- 오랫동안 서비스를 해온 아마존의 기능이 좀 더 상세하다
- 플랫폼 서비스로 출발한 구글은 자신들의 성격에 맞게 데이터 분석플랫폼을 웹상에 구현하고자 한다
- MS는 자신들의 다양한 개발 솔루션이나 데이터 분석 서비스를 클라우드를 통해 더 발전시키는 방향으로 진행한다

## 2. 빅데이터 분석의 종류와 특징

**데이터 분석의 정의**
- 데이터 분석의 정의
    - 대규모 데이터에서 유용한 정보를 뽑아내는 것이 데이터 마이닝이다.
    - 데이터 마이닝이란 의미 있는 저장소에 저장된 대규모의 데이터를 샅샅이 뒤져서 의미 있는 상관관계, 패턴 그리고 트렌드를 발견하는 작업을 의미한다.
    - 데이터 분석은 통계 그리고 수학 기법과 함께 패턴 인식 기술 역시 사용한다.
- 데이터 분석이 사용되는 영역
    - 데이터 소스 기준
        + 조직 내부 데이터 : 기업 내에서 경영 활동의 결과로 발생되고 축적되는 데이터
            ex) CRM 데이터, 수율 데이터, 시스템 로그 등
        + 조직 외부 데이터 : 퍼블릭 환경에서 사용자들에 의해 생성되고 접근 가능한 데이터
            ex) 인터넷 접속 데이터, 소셜 데이터, 데이터 마켓플레이스 데이터 등
    - 분석 목적 기준
        + 데이터 활용을 통해 신규 상품/서비스 개발
            ex) 고객 맞춤형 상품 출시, 개인화 서비스 등
        + 데이터 활용을 통해 현재 경영 활동의 개선
            ex) 프로세스 개선, 의사결정 툴 활용 등

**데이터 분석 프로세스**
1. 목적 정의
    + 데이터 분석은 대부분 반복적이고 대규모의 데이터를 사용해야 해서 상당한 시간과 비용이 소요되기 떄문에 목적을 정의하는 일이 아주 중요하다
    + 사용자와 아주 밀접한 관계에 있는 마케팅 부서나 해당 도메인의 성격과 데이터 생성 과정 자체를 이해하는 도메인 전문가에 의해 정해진다
2. 데이터 준비
    + 전처리
        + 샘플링 : 샘플로 상요할 데이터를 고르는 것 (빅데이터 분석에서는 모든 데이터를 사용)
        + 필터링 : 필요 없는 데이터를 없애버리는 것
3. 탐색적 자료 분석(EDA)
    + 데이터 내에 숨겨져 있는 정보를 문자 그대로 '탐색'한다
    + 아무런 관계가 없어 보이는 데이터들의 의미를 찾아내기 위해 이 과정을 반복적으로 수행한다
    + 데이터의 특징을 통계적으로 관찰하기도 하고 그래픽적으로 데이터를 분석하기도 한다 (박스 플롯이나 스캐터 플롯을 많이 사용)
    + 모델링에 사용할 데이터를 준비하거나 기존 데이터 중에 쓸모없는 데이터의 컬럼을 줄인다
    + 데이터 분석 작업을 검증하는 데이터 역시 이 과정에서 구체화된다
4. 데이터 분석 목표 구체화 및 모델링
    + EDA의 결과를 토대로 데이터 분석 목표를 구체화한다
    + 데이터 분석을 위한 기법의 카테고리를 지정하고 카테고리별로 사용할 기법을 정한다 -> 모델링
5. 데이터 분석 검증
    + 데이터 분석작업의 결과를 검증
    + 분석 모델과 알고리즘의 선택 및 튜징 작업을 반복적으로 진행
6. 모델링 작업 현업 적용
    + 검증이 완료된 모델을 실제 현어에 적용해 분류나 결정을 자동화한다
