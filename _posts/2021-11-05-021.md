---
layout: single
title:  "20211105 모델 선택"
categories: AI_bootcamp
---

1. 교차검증(Cross-validation) : 교차검증은 학습 데이터와 검증 데이터를 여러개로 구성해서 학습과 평가를 수행하는 것
- 평가 결과에 따라 하이퍼 파라미터로 모델을 최적화 할 수 있다
- hold-out CV : 훈련/검증/테스트 세트로 나누어 학습을 진행하고 검증하는 방법
    + 학습에 사용가능한 훈련세트의 크기가 충분하지 않을 경우 문제가 될 수 있다
    + 검증세트의 크기가 충분히 크지 않다면 예측 성능에 대한 추정이 부정확할 것
- K-fold CV : 데이터를 k개로 등분하여 k-1개의 부분집합을 훈련에 사용하고 나버지 부분집합을 테스트 데이터로 검증하는 방법
    + 전체 데이터셋을 row 순서대로 분할하기 때문에 불균형 문제가 발생할 수 있다
- Stratified K-fold CV : 레이블의 분포를 균등하게 해주고 K폴드를 실행하여 검증하는 방법
    + 레이블의 분포차이가 큰 데이터에선 반드시 Stratified Kfold를 이용해야 한다
- `cross_val_score` : 내부적으로 Stratified KFold를 이용하여 Estimator를 학습, 예측, 평가하는 작업

2. 하이퍼파라미터 튜닝
- 최적화 : 훈련 데이터로 더 좋은 성능을 얻기 위해 모델을 조정하는 과정
- 일반화 : 학습된 모델이 처음 본 데이터에서 좋은 성능을 내는지
- 하이퍼파라미터 : 알고리즘별로 최적의 학습을 위해 직접 입력하는 파라미터
    - 선형회귀, 랜덤포레스트 모델들의 튜닝 추천 하이퍼파라미터
        + Random Forest
            + `class_weight` (불균형 클래스인 경우)
            + `max_depth` (너무 깊어지면 과적합)
            + `n_estimators` (적을경우 과소적합, 높을경우 긴 학습시간)
            + `min_samples_leaf` (과적합일경우 높임)
            + `max_features` (줄일 수록 다양한 트리생성)
        + Logistic Regression
            + `C` (Inverse of regularization strength)
            + `class_weight` (불균형 클래스인 경우)
            + `penalty`
        + Ridge / Lasso Regression
            + `alpha`
- Randomized Search CV : 검증하려는 하이퍼파라미터들의 값 범위를 지정해주면 무작위로 값을 지정해 그 조합을 모두 검증
- GridSearch CV : 검증하고 싶은 하이퍼파라미터들의 수치를 정해주고 그 조합을 모두 검증
![](https://i.esdrop.com/d/9760phgt5lnm/CfJ9biN0Rr.png)

3. 성능지표
- Accuracy: 모든 분류 건수 중에서 분류기가 몇개의 정답을 맞혔는가 (맞거나 틀리다고 정확히 분류했는가)
- Recall: 맞다고 분류해야 하는 건수 중에서 분류기가 몇개나 제대로 분류했는가
    + 실제 데이터에 Negative 비율이 너무 높아서 희박한 가능성으로 발생할 상황에 대해 제대로 된 분류를 해주는지 평가할 때 사용
- Precision: 분류기가 맞다고 분류한 건수 중에서 실제로 맞는 건수가 몇개나 되는가
     + Recall과 Precision은 상충하는 개념이기 때문에 하나가 높아지면 다른 하나는 낮아진다.
- F1 score: Recall과 Precision의 균형값 (조화평균)





















4. Data leakage : 훈련 데이터에 타겟에 대한 정보가 포함됐지만, 그 정보를 실제 예측에서는 사용할 수 없는 경우 발생하는 정보 누수
- Target leakage : 예측 시점에서 사용할 수 없는 데이터가 데이터 셋에 포함되어 있을 때 발생
    + 타겟 값이 결정된 후 생성된 모든 변수들을 데이터 셋에서 제외해야 함
![](https://i.esdrop.com/d/9760phgt5lnm/En2V1i5SKP.png)
- Train-Test Contamination : 검증 데이터와 훈련 데이터를 제대로 구별하지 않았을 때 발생
    + 만약 검증 데이터가 train-test split 함수로 생성됐다면 검증 데이터를 모든 fitting에서 제외하고, 전처리 단계의 fitting에 포함시켜야 함\
        scikit-learn의 파이프라인을 이용 -> 교차 검증을 사용할 때는 파이프 라인 내에서 전처리를 수행하는 것이 훨씬 중요함
