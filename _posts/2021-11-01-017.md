---
layout: single
title:  "20211101 분류 모델의 성능 평가 지표"
categories: AI_bootcamp
---

# 성능 측정 지표 선택

1. 평균 제곱근 오차(RMSE) : 회귀 문제의 전형적인 성능 지표. 오차가 커질수록 이 값은 더욱 커지므로 예측에 얼마나 많은 오류가 있는지 가늠하게 해준다
![](https://i.esdrop.com/d/9760phgt5lnm/kqxOqRc4cX.png)
2. 평균 절대 오차(MAE) : 이상치가 많은 데이터에 사용
![](https://i.esdrop.com/d/9760phgt5lnm/oIXf2o9gpM.png)
3. 정확도 : 정확한 예측의 비율. 불균형한 데이터셋을 다룰 때는 사용하지 않는다
4. 오차행렬 : 클래스 A의 샘플이 클래스 B로 잘못 분류된 횟수를 세는 것
![](https://i.esdrop.com/d/9760phgt5lnm/RSKJ1kseww.png)
    + 오차행렬의 행은 실제 클래스를 나타내고 열은 예측한 클래스를 나타낸다
    + 완벽한 분류기라면 오차 행렬의 주대각선(왼쪽 위에서 오른쪽 아래로)만 0이 아닌 값이 된다
    + `cross_val_predict()` 함수를 사용하여 예측값을 만들고 실제 타깃과 비교
5. 정밀도와 재현율
- 정밀도(precision) : positive로 예측한 경우 중 올바르게 positive를 맞춘 비율
- 재현율(recall) : 실제 positive인 것 중 올바르게 맞춘 것의 비율(분류기가 정확하게 감지한 양성 샘플의 비율)
- F1 점수(f1 score) : 정밀도와 재현율의 조화 평균
        + 정밀도와 재현율이 비슷한 분류기에서는 F1 점수가 높다 -> 항상 바람직하지만은 않음
        + 상황에 따라 정밀도가 중요할 수도 있고 재현율이 중요할 수도 있음
- 정밀도/재현율 트레이드오프\
    `SGDClassifier`는 결정 함수를 사용하여 각 샘플의 점수를 계산하는데, 이 점수가 임곗값보다 크면 샘플을 양성 클래스에 할당하고 그렇지 않으면 음성클래스에 할당한다.
    + 임곗값을 높이면 거짓 양성이 진짜 음성이 되어 정밀도가 높아지지만 재현율이 줄어듬
    + 반대로 임곗값을 내리면 재현율이 높아지고 정밀도가 줄어듬
    + 좋은 정밀도/재현율 트레이드오프를 선택하는 방법 : 재현율에 대한 정밀도 곡선을 그려본다 - 급격히 줄어들기 시작하는 점을 선택
    
6. ROC 곡선
- 정밀도에 대한 TPR의 곡선이 아니라 **FPR**에 대한 TPR의 곡선
    + FPR : 양성으로 잘못 분류된 음성 샘플의 비율 (1-TNR)
    + TPR(재현율) : 음성으로 정확하게 분류한 음성 샘플의 비율
- 트레이드 오프 : 재현율(TPR)이 높을수록 분류기가 만드는 거짓 양성(FPR)이 늘어난다 (임계값을 낮춰 모두 True로 판단하게 하기 때문)
    + 최적의 임계값 : TPR은 최대화하고 FPR은 최소화하는 임계값
- 좋은 분류기는 완전한 랜덤 분류기의 ROC 곡선에서 최대한 멀리 떨어져야 한다 (=왼쪽 위에 가까울 수록 좋은 분류기이다)
- AUC : 곡선 아래의 면적(area under the curve)
    + 여러 개의 분류기를 비교할 수 있음 (두 분류기의 ROC AUC 점수를 비교하여 어떤 분류기가 더 좋은 분류기인지 비교)
    + 완벽한 분류기 : 1
    + 완전한 랜덤 분류기 : 0.5
- ROC곡선 vs. 정밀도/재현율(PR) 곡선
     + PR곡선 : 양성 클래스가 드물거나 거짓 음성보다 거짓 양성이 더 중요할 때 사용
     + ROC곡선 : 그 외
