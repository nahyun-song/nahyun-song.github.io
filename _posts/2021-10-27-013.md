---
layout: single
title:  "20211027 선형회귀/로지스틱"
categories: AI_bootcamp
---

# 1. 회귀문제와 분류문제의 차이

1. 회귀문제 : 종속변수가 수치형 변수인 문제
- 독립변수에 대한 제한은 없다
- 가격 예측, 구매 금액 예측, 평점 예측 등에 사용된다
- 평가 방법
    + 예측값과 실제값을 비교 (오차제곱합 등)
    + 평균으로 예측한 오차와 모형으로 예측한 오차를 비교
2. 분류문제 : 종속변수가 범주형 변수인 문제
- 범주가 여러 개인 문제와 두 개인 문제로 나눌 수 있지만 보통 범주를 두 개로 줄여 사용한다
- 희귀 사건 예측에 자주 활용된다 (보험 사기 예측, 재구매 예측, 가입 예측, 기업 부실 예측 등)
- 평가 방법
    + 오분류율 : 전체 대상 중 잘 못 분류한 건이 몇 건인지 확인
    + 향상도 : 사전확률과 모형이 예측한 결과를 비교
    + 검출률

# 2. 과적합/과소적합/경사하강법

1. 과적합(과대적합) : 모델이 훈련 데이터에 너무 잘 맞지만 일반성이 떨어지는 경우
- 보통 훈련 데이터에 있는 노이즈에 비해 모델이 너무 복잡할 때 일어남
- 해결 방법
    - 훈련 데이터에 있는 특성 수를 줄인다
    - 모델에 제약을 가하여 단순화시킨다 (하이퍼파라미터 튜닝)
    - 훈련 데이터 양을 늘린다
    - 훈련 데이터의 노이즈를 줄인다 (오류 수정, 이상치 제거)

2. 과소적합 : 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못하는 경우
- 해결방법
    - 모델 파라미터가 더 많은 강력한 모델을 선택한다
    - 학습 알고리즘에 더 좋은 특성을 제공한다 (특성 공학)
    - 모델의 제약을 줄인다 (하이퍼파라미터 튜닝)

3. 분산/편향 트레이드오프
- 분산이 높은경우 : 모델이 학습 데이터의 노이즈에 민감하게 적합하여 테스트 데이터에서 일반화를 잘 못함 -> 과적합
- 편향이 높은경우 : 모델이 학습 데이터에서, 특성과 타겟 변수의 관계를 잘 파악하지 못함 -> 과소적합

4. 경사하강법 (Gradient Descent)
- 비용 함수를 최소화하기 위해 반복해서 파라미터를 조정해가는 것
    - 파라미터 벡터에 대해 비용 함수의 현재 그래디언트(비용함수의 기울기)를 계산한다
    - 그래디언트가 감소하는 방향으로 진행한다
    - 그래디언트가 0이 될 때까지 반복
- 학습률 (Learning rate) : 학습 스텝의 크기
    - 학습률이 너무 작으면 : 알고리즘이 수렴하기 위해 반복을 많이 진행해야 하므로 시간이 오래 걸림
    - 학습률이 너무 크면 : 알고리즘을 더 큰 값으로 발산하게 만들어 적절한 해법을 찾기 어려움
- 경사하강법의 문제점 - 무작위로 선택한 초기값
    - global minimum에 도달하기 전에 local minimum에 수렴할 수도 있다
    - 실제 도달해야하는 지점에서 먼 곳을 초기값으로 잡으면 시간이 오래 걸리고 도달하기 전에 학습이 끝날 수도 있다
    - 하나의 global minimum이 존재하고 기울기가 갑자기 변하지 않는 비용함수를 가지고 있다면 목표지점에 가깝게 도달할 수 있음\
      ex) 선형 회귀를 위한 MSE 비용 함수

# 3. 원핫인코딩(One-hot encoding)

1. 인코딩 : 사람이 인지할 수 있는 형태의 데이터를 컴퓨터가 사용하고 이해할 수 있는 0과 1로 변환하는 과정
2. 원핫인코딩 : 피처의 고유값에 해당하는 칼럼에만 1을 부여하고 나머지는 다 0으로 표현해주는 인코딩
    > 1. 각 단어에 고유한 인덱스 부여(정수 인코딩)
    > 2. 표현하고 싶은 단어의 인덱스의 위치에 1을 부여하고 다른 단어의 인덱스의 위치에 0을 부여
- 단점
    + 단어 간 유사도 계산 불가
    + 단어의 개수가 늘어날수록 벡터의 차원이 늘어나기 때문에 많은 저장공간이 필요 -> 저장 공간의 측면에서 매우 비효율적

# 4. 훈련/검증/테스트(train/validate/test) 데이터

1. 훈련 세트 : 시스템이 학습하는 데 사용하는 샘플
2. 검증 세트 : 모델을 비교하는 데 사용하는 샘플
3. 테스트 세트 : 실전에 배치되기 전에 모델이 새로운 샘플에 대해 만들 일반화 오차를 추정하기 위해 사용하는 샘플\
   -> train으로 학습하면서 하이퍼파라미터를 튜닝, validation에서 예측 오류 측정, test로 일반화 확인

4. 훈련/테스트 세트를 분리하는 이유
- 테스트 세트를 사용해 하이퍼파라미터를 튜닝하면 테스트 세트에 과대적합될 위헙이 있고 일반화 오차를 낙관적으로 측정하게 된다
- 학습에 사용하는 데이터와 모델을 평가하는데 사용하는 데이터가 달라야 모델의 예측 성능을 제대로 평가할 수 있다

5. 훈련/검증/테스트 세트를 분리하는 이유
- 훈련 데이터로 모델을 한 번에 완전하게 학습시기키 어렵기 때문에
- 모델 검증과 모델 평가를 하는 데이터를 분리하기 위해
    - 모델 검증 : 모델의 성능을 평가하고, 그 결과를 토대로 모델을 튜닝하는 단계 - 검증 세트 사용
    - 모델 평가 : 최종적으로 일반화 오류를 측정하는 단계 - 테스트 세트 사용

# 5. 선형회귀

1. 선형회귀 : 독립적인 변수 x에 대해, 종속적으로 결정되는 종속 변수 y를 이용하여 선형 관계를 모델링하는 것
   ex) 광고의 횟수가 늘면 구매율이 높아진다, 운동을 하면 몸무게는 감소한다 등
    - 1. 단순 선형 회귀 : 데이터를 설명하는 모델을 직선 형태로 가정
        - 입력값이 1개인 경우에만 적용 가능
        - 입력값과 결과값의 관계를 알아보는 데 용이
        - 두 변수 간의 관계를 직관적으로 해석하고자 하는 경우 활용
        ![](https://i.esdrop.com/d/9760phgt5lnm/DTbro1q5n5.png)
        ![](https://i.esdrop.com/d/9760phgt5lnm/UJjabn7DgQ.png)
    여기서 `W`는 가중치, `b`는 편향을 의미한다.
    단순 선형 회귀는 x, y 관계를 잘 예측하기 위해서 적절한 `W`,`b`를 찾아내는 것을 뜻한다.

        + 가중치 : 각각 입력 값에 곱해지는 수
        + 편향 : 최종적으로 계산된 값을 조절하는 역할. 활성화 함수에 설정된 임계값을 얼마나 쉽게 넘게 할 것인지 조절해 줌
            + 편향이 높다면 : 임계값이 낮아지기 때문에 활성화되는 뉴런이 줄어들어 모델이 간단해짐
            + 편향이 낮다면 : 임계값이 높아지기 때문에 활성화되는 뉴런이 많아져 모델이 복잡해짐
    - 2. 다중 선형 회귀 : 하나의 특성이 아닌 여러 개의 특성을 활용해서 회귀 모델을 찾는 것
        - 여러 개의 입력값과 결과값 간의 관계 확인 가능
        - 어떤 입력값이 결과값에 어떠한 영향을 미치는지 알 수 있음
        - 여러 개의 입력값 간의 상관관계가 높을 경우 결과에 대한 신뢰성을 잃을 수 있음
        ![](https://i.esdrop.com/d/9760phgt5lnm/rsNnJrbVTg.png)

# 6. 로지스틱 회귀

- 분류 문제에 사용할 수 있는 회귀모델
- 분류 알고리즘 중에서도 정확도가 높음
- 샘플이 특정 클래스에 속할 확률을 추정함
> 1. 훈련 세트 특성과 분포를 나타내는 최적의 직선을 찾는다
> 2. 그 직선을 기준으로 데이터를 두 영역으로 분류한다
- 선형회귀와 달리, S자 함수를 이용함
    + 시그모이드 함수 : 입력된 데이터를 0과 1사이의 값으로 출력하는 비선형 함수
        x가 커지면 y는 1에 근사하게 되고, 작아지면 0에 근사하게 되어 s자 모양의 그래프가 됨
        ![](https://i.esdrop.com/d/9760phgt5lnm/FQrWlUAtLI.png)
- 성능평가 : 이진분류 결과를 평가하기 위해 오차행렬에 기반한 성능지표인 정밀도, 재현율, F1스코어, ROC_AUC를 사용
