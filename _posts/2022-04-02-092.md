---
layout: single
title:  "20220402 처음 만나는 자연어 처리"
categories: preonboarding
---

## 1-1 딥러닝 기반 자연어 처리 모델
1. 기계의 자연어 처리
    - 자연어 처리 모델은 자연어를 입력 받아서 해당  입력이 특정 범주일 확률을 반환하는 확률함수다.
    - 딥러닝 : 데이터 패턴을 스스로 익히는 인공지능의 한 갈래
    - 딥러닝 기반 자연어 처리 모델 : BERT, GPT
2. 딥러닝 모델의 학습
    - 합습데이터 : 레이블을 달아놓은 자료
    - 학습 : 데이터의 패턴을 스스로 익히게 하는 것
        출력이 정답에 가까워지도록 모델을 업데이트하는 과정

## 1-2 트랜스퍼 러닝
1. 트렌스퍼 러닝
    - 특정 태스크를 학습한 모델을 다른 태스크 수행에 재사용하는 기법
    - 모델의 학습속도가 빨라지고 새로운 태스크를 더 잘 수행하는 결향이 있다
    - 업스트림 태스크 : 다음 단어 맞히기, 빈칸 채우기 등 대규모 말뭉치 이해
    - 다운스트림 태스크 : 문서 분류, 개체명 인식 등 자연어 처리의 구체적인 문제들
2. 업스트림 태스크
    - 자연어의 풍부한 문맥을 모델에 내재화
    - 언어 모델(language model) : 다음 단어 맞히기로 업스트림 태스크를 수행한 모델
    - 마스크 언어 모델(masked language model) : 빈칸 채우기로 업스트림 태스크를 수행한 모델
        자기 지도 학습 : 데이터 내에서 정답을 만들고 이를 바탕으로 모델을 학습하는 방법
3. 다운 스트림 태스크
    - 우리가 풀어야 할 자연어처리의 구체적인 과제들
    - 파인튜닝 : 다운스트림 태스크의 학습 방식 중 하나
        프리트레인을 마친 모델을 다운스트림 태스크에 맞게 업데이트하는 기법
    1. 문서 분류
        - 자연어를 입력 받아 해당 입력이 어떤 범주(긍정, 부정, 중립 등)에 속하는지 그 확률값을 반환
        - 프리트레인을 마친 마스크 언어 모델 위에 작은 모듈을 하나 더 쌓아 문서 전체의 범주를 분류
    2. 자언어 추론
        - 문장 2개를 입력 받아 두 문장 사이의 관계가 참, 거짓, 중립 등 어떤 범주인지 그 확률값을 반환
    3. 개체명 인식
        - 자연어를 입력 받아 단어별로 기관명, 인명, 지명 등 어떤 개체명 범주에 속하는지 그 확률 값을 반환
    4. 질의 응답
        - 자연어를 입력 받아 각 단어가 정답의 시작일 확률과 끝일 확률을 반환
        - 마스크 언어 모델 위에 단어별로 작은 모듈을 쌓아 전체 단어 가운데 어떤 단어가 시작인지 끝인지 분류
    5. 문장 생성
        - GPT 계열의 언어 모델 사용
        - 자연어를 입력 받아 어휘 전체에 대한 확률값을 반환
        - 언어 모델을 그대로 사용해 문맥에 이어지는 적절한 다음 단어를 분류

## 1-3 학습 파이프라인 소개
1. 각종 설정값 정하기 : 사용할 모델, 데이터, 학습 결과를 저장할 공간, 하이퍼파라미터
2. 데이터 내려받기 : 스운스트림 데이터 내려받기
3. 모델 준비하기 : 허깅페이스 활용
4. 토크나이저 준비하기
    - 토큰 : 문장보다 작은 단위. 여러 기준이 있다
    - 토큰화 : 문장을 토큰 시퀀스로 분석하는 과정
5. 데이터로터 준비하기
    - 데이터로더 : 데이터를 배치 단위로 모델에 밀어 넣어 주는 역할
        전체 데이터 가운데 일부 인스턴스를 뽑아 배치를 구성함
    - 데이터셋 : 데이터로더의 구성 요소로 여러 인스턴스를 보유함
6. 태스크 정의하기 
    - 파이토치 라이트닝 : 딥러닝 모델을 학습할 때 반복적인 내용을 대신 수행해줘 사용자가 모델 구축에만 신경쓸 수 있도록 돕는 라이브러리
7. 모델 학습하기
    - 트레이너 : 파이토치 라이트닝에서 제공하는 객체. 실제 학습을 수행함
