---
layout: single
title:  "20220222 week1-2"
categories: preonboarding
---

# Extractive Text Summarization

- 문제 정의
    - 문서가 주어지면 문서의 요약을 가장 잘 나타내는 단어 또는 문장의 하위 집합을 선택하는 것
    
- 데이터셋 소개 : CNN/Daily Mail
    - CNN과 Daily Mail의 기자들이 작성한 대로 30만 개가 넘는 독특한 뉴스 기사를 포함하고 있는 영어 데이터 세트
    - 모델 성능은 특정 기사에 대한 출력 요약의 ROUGE 점수가 원본 기사 작성자가 작성한 highlight와 비교하여 얼마나 높은지 측정
    - 원래 버전은 기계 읽기 및 이해와 추상적 질문 답변을 위해 만들어졌지만 현재 버전은 추출적 요약과 추상적 요약을 모두 지원함
    - 말뭉치는 287,113개의 훈련 쌍, 13,368개의 검증 쌍 및 11,490개의 테스트 쌍으로 구성
    
![](https://i.esdrop.com/d/f/Wt5zrblYBe/UVAX5d6CKH.png)

- SOTA 모델 소개
    1. HAHSum
        - 공동 추출 및 구문 압축을 기반으로 단일 문서 요약을 하기 위한 신경 모델
        - 학습을 위해 오라클 추출 압축 요약을 구성한 다음 두 구성 요소를 학습
        - 기성 압축 모듈을 능가하며, 인적 및 수동 평가에서는 모델의 출력이 문법적으로 유지된다
            1. 문서에서 문장을 선택
            2. 구성 요소 파스를 기반으로 가능한 압축을 식별
            3. 신경 모델로 이러한 압축 점수를 매겨 최종 요약을 생성  
        - 성능 : ROUGE-1	44.68 / ROUGE-2	21.30 / ROUGE-L	40.75
         
        - 텍스트 압축 모듈 : 신경 분류기는 문장 및 광범위한 문서 맥락에서 압축 옵션('with their furry friends')을 채점하고 삭제 여부를 결정함
        ![](https://i.esdrop.com/d/f/Wt5zrblYBe/ntxu7FKsYs.png)
         
    2. MatchSum
        - 문장을 개별적으로 추출하고 문장 간 관계를 모델링하는 프레임워크를 따르는 대신, 추출 요약 작업을 의미론적 텍스트 매칭 문제로 정의
        - 출처 문서와 원문을 요약한 **후보 문장**이 semantic space에서 매칭될 것이라 가정
        ![](https://i.esdrop.com/d/f/Wt5zrblYBe/LS6dDsFGQz.png)
        - pearl summary : 데이터셋 자체의 속성을 확인할 수 있는 지표로써 이 논문에서 새롭게 제시함\
            (그 전에는 sentence level score로 판단했으나 best summary ranking과는 다른 결과가 나왔기 때문에) 
        - pearl summary 비율을 기반으로 문장 수준과 요약 수준 사이의 고유한 격차를 포괄적으로 분석
        - 성능 : ROUGE-1 44.41 /	ROUGE-2 20.86 / ROUGE-L 40.55
 
 
💡참고

- CNN/Daily Mail 데이터셋 관련

    https://huggingface.co/datasets/cnn_dailymail#data-instances

    https://github.com/huggingface/datasets/tree/master/datasets/cnn_dailymail#dataset-summary

- HAHSum 모델 관련 

    https://arxiv.org/pdf/1902.00863v2.pdf

- MatchSum 모델 관련 

    https://youtu.be/8E2Ia4Viu94
    
    https://arxiv.org/pdf/2004.08795v1.pdf
